{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd286fbd",
   "metadata": {},
   "source": [
    "# Agent Bot Demo\n",
    "\n",
    "This notebook demonstrates a simple conversational agent using LangGraph and Ollama. The agent maintains conversation history and can save the dialogue to a file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e598b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing import TypedDict, List, Union\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004aa125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")\n",
    "\n",
    "# Verify LLM is loaded\n",
    "assert llm is not None, \"LLM failed to initialize\"\n",
    "\n",
    "\n",
    "# Define agent state type\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[Union[HumanMessage, AIMessage]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define core functions\n",
    "def process(state: AgentState) -> AgentState:\n",
    "    \"\"\"Process response from LLM\"\"\"\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    print(f\"\\nAI: {response.content}\")\n",
    "    state[\"messages\"].append(AIMessage(content=response.content))\n",
    "    return state\n",
    "\n",
    "\n",
    "def save_conversation(\n",
    "    conversation_history: List[Union[HumanMessage, AIMessage]],\n",
    "    filename: str = \"chat_log.txt\",\n",
    "):\n",
    "    \"\"\"Save conversation history to a file\"\"\"\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(\"Conversation history:\\n\")\n",
    "        for m in conversation_history:\n",
    "            if isinstance(m, HumanMessage):\n",
    "                file.write(f\"User: {m.content}\\n\")\n",
    "            elif isinstance(m, AIMessage):\n",
    "                file.write(f\"AI: {m.content}\\n\\n\")\n",
    "        file.write(\"End of Conversation\")\n",
    "    print(f\"Conversation saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb19cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and compile the graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"process\", process)\n",
    "graph.add_edge(START, \"process\")\n",
    "graph.add_edge(\"process\", END)\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1669a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: Hello, how are you?\n",
      "\n",
      "AI: I'm just a language model, so I don't have emotions or feelings like humans do. However, I'm functioning properly and ready to assist you with any questions or tasks you may have! How can I help you today?\n",
      "Found keywords: ['assist', 'help', 'language', 'model']\n",
      "\n",
      "User: What can you help me with?\n",
      "\n",
      "AI: I can help with a wide range of topics and tasks. Here are some examples:\n",
      "\n",
      "1. **Answering questions**: I can provide information on various subjects, including history, science, technology, literature, and more.\n",
      "2. **Language translation**: I can translate text from one language to another.\n",
      "3. **Writing assistance**: I can help with writing tasks such as suggesting alternative phrases, rephrasing sentences, and providing grammar and spelling corrections.\n",
      "4. **Conversation**: I can engage in natural-sounding conversations, using context and understanding to respond to questions and statements.\n",
      "5. **Brainstorming**: I can generate ideas and suggestions on a given topic or subject.\n",
      "6. **Summarization**: I can summarize long pieces of text into shorter, more digestible versions.\n",
      "7. **Jokes and humor**: I can share jokes and try to be funny (though I may not always succeed).\n",
      "8. **Word games and puzzles**: I can play simple word games like Hangman, Word Jumble, or Word Scramble.\n",
      "9. **Language learning**: I can help with language learning by providing corrections, suggestions, and examples of grammar, vocabulary, and pronunciation.\n",
      "10. **General knowledge**: I can provide information on various topics, including but not limited to history, science, technology, literature, arts, music, and more.\n",
      "\n",
      "What sounds interesting to you? Or do you have something specific in mind that you'd like help with?\n",
      "Found keywords: ['assist', 'help', 'can']\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with sample conversations\n",
    "test_examples = [\n",
    "    {\n",
    "        \"messages\": [\"Hello, how are you?\"],\n",
    "        \"exp_keywords\": [\"assist\", \"help\", \"language\", \"model\"],\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\"What can you help me with?\"],\n",
    "        \"exp_keywords\": [\"assist\", \"help\", \"support\", \"can\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def validate_response(response: str, keywords: list) -> tuple[bool, list]:\n",
    "    \"\"\"Validate that response contains expected keywords\"\"\"\n",
    "    found_keywords = []\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in response.lower():\n",
    "            found_keywords.append(keyword)\n",
    "    return len(found_keywords) >= 1, found_keywords\n",
    "\n",
    "\n",
    "conversation_history = []\n",
    "\n",
    "for example in test_examples:\n",
    "    for message in example[\"messages\"]:\n",
    "        print(f\"\\nUser: {message}\")\n",
    "        conversation_history.append(HumanMessage(content=message))\n",
    "        result = agent.invoke({\"messages\": conversation_history})\n",
    "        conversation_history = result[\"messages\"]\n",
    "\n",
    "        # Get the last AI response\n",
    "        response = conversation_history[-1].content\n",
    "\n",
    "        # Basic response validation\n",
    "        assert isinstance(\n",
    "            conversation_history[-1], AIMessage\n",
    "        ), \"Invalid response format\"\n",
    "        assert len(response) > 0, \"Empty response received\"\n",
    "\n",
    "        # Keyword validation\n",
    "        is_valid, found = validate_response(response, example[\"exp_keywords\"])\n",
    "        assert is_valid, (\n",
    "            f\"Response missing expected keywords. Found: {found}. \"\n",
    "            f\"Expected at least 1 from: {example['exp_keywords']}\"\n",
    "        )\n",
    "        print(f\"Found keywords: {found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa18d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation saved to test_conversation.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the test conversation\n",
    "save_conversation(conversation_history, \"test_conversation.txt\")\n",
    "assert os.path.exists(\"test_conversation.txt\"), \"Conversation file not saved\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
