{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b533ad9",
   "metadata": {},
   "source": [
    "# RAG Agent Demo\n",
    "\n",
    "This notebook demonstrates the RAG (Retrieval Augmented Generation) agent that answers questions about Stock Market Performance using a PDF document as knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b02b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    ToolMessage,\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    ")\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM and embeddings\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:latest\", temperature=0\n",
    ")  # Low temperature for consistency\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# Verify models are loaded\n",
    "assert llm is not None, \"LLM failed to initialize\"\n",
    "assert embeddings is not None, \"Embeddings model failed to initialize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Code\\AI_Agents_with_Python\\static\\Stock_Market_Performance_2024.pdf\n"
     ]
    }
   ],
   "source": [
    "# Load and process PDF\n",
    "pdf_path = os.path.join(\n",
    "    os.path.dirname(os.getcwd()), \"static\", \"Stock_Market_Performance_2024.pdf\"\n",
    ")\n",
    "print(pdf_path)\n",
    "assert os.path.exists(pdf_path), f\"PDF file not found: {pdf_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c38a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF loaded successfully with 9 pages\n"
     ]
    }
   ],
   "source": [
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "pages = pdf_loader.load()\n",
    "print(f\"PDF loaded successfully with {len(pages)} pages\")\n",
    "\n",
    "# Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "pages_split = text_splitter.split_documents(pages)\n",
    "assert len(pages_split) > 0, \"Text splitting produced no chunks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc68875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB vector store created successfully\n"
     ]
    }
   ],
   "source": [
    "# Set up ChromaDB vector store\n",
    "persist_directory = os.path.join(os.path.dirname(os.getcwd()), \"Agents\", \"Chroma\")\n",
    "collection_name = \"stock_market\"\n",
    "\n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=pages_split,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=collection_name,\n",
    ")\n",
    "print(\"ChromaDB vector store created successfully\")\n",
    "\n",
    "# Set up retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "assert retriever is not None, \"Retriever failed to initialize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86035bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define retriever tool and agent state\n",
    "@tool\n",
    "def retriever_tool(query: str) -> str:\n",
    "    \"\"\"Searches the Stock Market Performance 2024 document.\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    if not docs:\n",
    "        return \"No relevant information found.\"\n",
    "\n",
    "    results = [f\"Document {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs)]\n",
    "    return \"\\n\\n\".join(results)\n",
    "\n",
    "\n",
    "tools = [retriever_tool]\n",
    "llm = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fda7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent functions\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Check if more tool calls are needed.\"\"\"\n",
    "    result = state[\"messages\"][-1]\n",
    "    return hasattr(result, \"tool_calls\") and len(result.tool_calls) > 0\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"You are an AI assistant who answers questions about Stock Market Performance in 2024.\n",
    "Use the retriever tool to access the document. Cite specific parts in your answers.\"\"\"\n",
    "\n",
    "tools_dict = {tool.name: tool for tool in tools}\n",
    "\n",
    "\n",
    "def call_llm(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call LLM with current state.\"\"\"\n",
    "    messages = [SystemMessage(content=system_prompt)] + list(state[\"messages\"])\n",
    "    message = llm.invoke(messages)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "def take_action(state: AgentState) -> AgentState:\n",
    "    \"\"\"Execute tool calls from the LLM's response.\"\"\"\n",
    "\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    results = []\n",
    "\n",
    "    for t in tool_calls:\n",
    "        print(\n",
    "            f\"Calling Toll: {t['name']} with query: {t['args'].get('query', \"No query provided.\")}\"\n",
    "        )\n",
    "\n",
    "        if not t[\"name\"] in tools_dict:\n",
    "            print(f\"\\nTool: {t['name']} does not exist.\")\n",
    "            result = \"Incorrect Tool Name, Please Retry and Select tool from list of Available tools.\"\n",
    "\n",
    "        else:\n",
    "            result = tools_dict[t[\"name\"]].invoke(t[\"args\"].get(\"query\", \"\"))\n",
    "            print(f\"Result length: {len(str(result))}\")\n",
    "\n",
    "        results.append(\n",
    "            ToolMessage(tool_call_id=t[\"id\"], name=t[\"name\"], content=str(result))\n",
    "        )\n",
    "\n",
    "    print(\"Tools Execution Complete. Back to the model.\")\n",
    "    return {\"messages\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06696c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and compile the graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"llm\", call_llm)\n",
    "graph.add_node(\"retriever_agent\", take_action)\n",
    "\n",
    "# Add edges\n",
    "graph.add_conditional_edges(\n",
    "    \"llm\", should_continue, {True: \"retriever_agent\", False: END}\n",
    ")\n",
    "graph.add_edge(\"retriever_agent\", \"llm\")\n",
    "graph.set_entry_point(\"llm\")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92a0d667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What were the top performing sectors in 2024?\n",
      "Calling Toll: retriever_tool with query: Top performing sectors in 2024\n",
      "Result length: 4818\n",
      "Tools Execution Complete. Back to the model.\n",
      "Answer:\n",
      "The top performing sectors in 2024 were:\n",
      "\n",
      "1. Technology: The tech-heavy Nasdaq Composite outpaced the broader market, jumping nearly 29% for the year.\n",
      "2. Mega-cap technology stocks: A group of seven powerhouse companies often dubbed the \"Magnificent 7\" - Apple, Microsoft, Alphabet (Google), Amazon, Meta, Facebook, and NVIDIA.\n",
      "\n",
      "These sectors were among the top performers in 2024, driven by strong gains from mega-cap technology stocks.\n",
      "\n",
      "Found keywords: ['Technology', 'Nasdaq', 'Magnificent 7', 'tech', 'NVIDIA']\n",
      "\n",
      "Question: What was the overall market trend in Q1 2024?\n",
      "Calling Toll: retriever_tool with query: Q1 2024 market trend\n",
      "Result length: 4818\n",
      "Tools Execution Complete. Back to the model.\n",
      "Answer:\n",
      "The overall market trend in Q1 2024 was a strong one for equities, with the U.S. stock market extending the robust gains seen in the prior year. The benchmark S&P 500 index delivered roughly a 25% total return for 2024 (around +23% in price terms), marking the second consecutive year of over 20% returns for the S&P 500 - a feat not observed since the late 1990s.\n",
      "\n",
      "Found keywords: ['S&P 500', '25%', 'total return', 'gains']\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with sample questions and validate responses\n",
    "test_examples = [\n",
    "    {\n",
    "        \"question\": \"What were the top performing sectors in 2024?\",\n",
    "        \"exp_keywords\": [\"Technology\", \"Nasdaq\", \"Magnificent 7\", \"tech\", \"NVIDIA\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What was the overall market trend in Q1 2024?\",\n",
    "        \"exp_keywords\": [\"S&P 500\", \"25%\", \"total return\", \"gains\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def validate_response(response: str, keywords: list) -> tuple[bool, list]:\n",
    "    \"\"\"Validate that response contains expected keywords\"\"\"\n",
    "    found_keywords = []\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in response.lower():\n",
    "            found_keywords.append(keyword)\n",
    "    return len(found_keywords) >= 2, found_keywords\n",
    "\n",
    "\n",
    "for question in test_examples:\n",
    "    print(f\"\\nQuestion: {question['question']}\")\n",
    "    messages = [HumanMessage(content=question[\"question\"])]\n",
    "    result = app.invoke({\"messages\": messages})\n",
    "    response = result[\"messages\"][-1].content\n",
    "    print(f\"Answer:\\n{response}\\n\")\n",
    "\n",
    "    # Basic response validation\n",
    "    assert isinstance(result[\"messages\"][-1], BaseMessage), \"Invalid response format\"\n",
    "    assert len(response) > 0, \"Empty response received\"\n",
    "\n",
    "    # Keyword validation\n",
    "    is_valid, found = validate_response(response, question[\"exp_keywords\"])\n",
    "    assert is_valid, (\n",
    "        f\"Response missing expected keywords. Found only: {found}. \"\n",
    "        f\"Expected at least 2 from: {question['exp_keywords']}\"\n",
    "    )\n",
    "    print(f\"Found keywords: {found}\")\n",
    "\n",
    "    # Tool usage validation\n",
    "    tool_messages = [msg for msg in result[\"messages\"] if isinstance(msg, ToolMessage)]\n",
    "    assert len(tool_messages) > 0, \"Response should use retriever tool\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
